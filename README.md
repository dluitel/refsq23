# Introduction
This repository contains the implementation and evaluation artifacts for the REFSQ 2023 submission titled "Using Language Models for Enhancing the Completeness of Natural-language Requirements", authored by Dipeeka Luitel, Shabnam Hassani and Mehrdad Sabetzadeh.



# Prerequisites
- Python 3.8
- SpaCy 3.2.2
- PyTorch1.10.2+cu113
- GloVe (https://nlp.stanford.edu/projects/glove/) 
- Transformers 4.16.2 library by Hugging Face (https://huggingface.co/)
- WEKA 3-8-5 (https://www.cs.waikato.ac.nz/ml/weka/)



# Instructions
The following steps explain how to use this repository to utilize BERT's MLM for assisting with completeness checking of requirements. The code has been streamlined to simplify the process of filtering relevant predicted terms, generated by BERT, for a supplied RS.
1. Run RQ1_Script.py using the provided documents (or with a requirements specification). This runs BERT's MLM and generates a raw set of predictions, a feature matrix (.ARFF file), and a summary table for metrics.
2. Load WEKA and create a new Explorer project.
3. In the Classify tab: 
    - Unzip and load P1 Model corresponding to desired filtering level (strict, moderate, and lenient).  
    - Set .ARFF file (generated in Step 1) as the supplied test set.
4. Click "More options..." and select "CSV" under "Output predictions".
5. Select "Re-evaluate model on current test set".
6. Copy output of "Predictions on user test set" into new CSV file.
7. Predictions marked True correspond to relevant predictions in the raw predictions file (Step 1 above). These predictions, after duplicate removal, constitute the final reccommendations made to the user.
